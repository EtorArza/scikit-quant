{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "388a4d5b",
   "metadata": {},
   "source": [
    "# Let's apply the GP-based optimizer to our small Hubbard model.\n",
    "\n",
    "Make sure your jupyter path is the same as your virtual environment that you used to install all your packages. \n",
    "If nopt, do something like this in your terminal:\n",
    "\n",
    "`$ ipython kernel install --user --name TUTORIAL --display-name \"Python 3.9\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242e5ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check your python\n",
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacb0cf8",
   "metadata": {},
   "source": [
    "Gaussian Process (GP) models were introduced in the __[Gaussian Process Models](optimization.ipynb)__ notebook. The GP-based optimizer uses these techniques as implemented in the included __[opti_by_gp.py](opti_by_gp.py)__ module, which also provides helpers for plotting results. Note that this module uses the ImFil optimizer underneath, a choice that can not currently be changed.\n",
    "\n",
    "As a first step, create once more a __[Hubbard Model](hubbard_model_intro.ipynb)__ setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e830db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hubbard as hb\n",
    "import logging\n",
    "import noise_model as noise\n",
    "import numpy as np\n",
    "import opti_by_gp as obg\n",
    "from IPython.display import Image\n",
    "\n",
    "logging.getLogger('hubbard').setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581cb31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a model appropriate for the machine used:\n",
    "#    laptop -> use small model\n",
    "#    server -> use medium model\n",
    "\n",
    "MODEL = hb.small_model\n",
    "#MODEL = hb.medium_model\n",
    "\n",
    "# Hubbard model for fermions (Fermi-Hubbard) required parameters\n",
    "xdim, ydim, t, U, chem, magf, periodic, spinless = MODEL()\n",
    "\n",
    "# Number of electrons to add to the system\n",
    "n_electrons_up   = 1\n",
    "n_electrons_down = 1\n",
    "n_electrons = n_electrons_up + n_electrons_down\n",
    "\n",
    "# Total number of \"sites\", with each qubit representing occupied or not\n",
    "spinfactor = spinless and 1 or 2\n",
    "n_qubits = n_sites = xdim * ydim * spinfactor\n",
    "\n",
    "# Create the Hubbard Model for use with Qiskit\n",
    "hubbard_op = hb.hamiltonian_qiskit(\n",
    "    x_dimension        = xdim,\n",
    "    y_dimension        = ydim,\n",
    "    tunneling          = t,\n",
    "    coulomb            = U,\n",
    "    chemical_potential = chem,\n",
    "    magnetic_field     = magf,\n",
    "    periodic           = periodic,\n",
    "    spinless           = spinless)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072a7d32",
   "metadata": {},
   "source": [
    "The GP modeling needs persistent access to the evaluated points, so tell the objective to save them. Otherwise, the objective is the same as before. Choose the maximum number of objective evaluations, the initial and set the bounds. Then run the optimization using GP (as mentioned before, this uses ImFil underneath)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bcd494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise-free objective with enough Trotter steps to get an accurate result\n",
    "objective = hb.EnergyObjective(hubbard_op, n_electrons_up, n_electrons_down,\n",
    "    trotter_steps=3, save_evals=True)\n",
    "\n",
    "# initial and bounds (set good=True to get tighter bounds)\n",
    "initial_amplitudes, bounds = MODEL.initial(\n",
    "    n_electrons_up, n_electrons_down, objective.npar(), good=False)\n",
    "\n",
    "# max number of allowed function evals\n",
    "maxevals = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d899819",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = obg.opti_by_gp(objective.npar(), bounds, objective, maxevals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965fa044",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Results with GP:')\n",
    "print(\"Estimated energy: %.5f\" % result[1])\n",
    "print(\"Parameters:      \", result[0])\n",
    "print(\"Number of iters: \", result[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d104db",
   "metadata": {},
   "source": [
    "Now let's analyze the results be looking at the sample evaluations and convergence plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bb9172",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='samples.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6641bb",
   "metadata": {},
   "source": [
    "The left plot shows:\n",
    "1) the points sampled with GP (pink squares): you can see that we have some points everywhere in the space, but a denser pink square cloud where the function has its minimum\n",
    "\n",
    "2) yellow circles (5) -- these are the points from which the local search with ImFil starts: we choose the best point found by the GP, and another 4 points based on their function value and distance to already selected start points. 5 is a parameter, if you want to do only one local search, you can just start from the best point found by the GP iterations. Also: not all 5 points will necessarily be used for ImFil, the optimization stops when the maximum number of allowed evaluations has been reached. \n",
    "\n",
    "3) the green squares are the points ImFil decided to sample -- you can see that they cover most of the space. Wouldn't it be nice to force ImFil to search only a smaller radius?!\n",
    "\n",
    "4) the red dot indicates the best point found during optimization\n",
    "\n",
    "5) the contours are created by using a GP model and all sample information that we collected - so this is not the true contours, but the best guess of what the true contours may look like\n",
    "\n",
    "The right plot shows the GP approximation of the energy surface - again, not the true surface, just our best guess based on training a GP on all input-output pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81af99e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='progress.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cb684d",
   "metadata": {},
   "source": [
    "This plot shows the progress we are making with respect to improving the energy versus the number of function evaluations. \n",
    "We show the best energy value found so far, thus, the graph is monotonically decreasing and has a step-like shape. whenever the graph is flat, it means that during these iterations no energy improvements were found. If you were to plot simply the energy at each function evaluation, the graph would go up and down because we use sampling based algorithms and not gradient-based algorithms. Thus, not in every iteration we find an improvement. \n",
    "There is a large down-step in the beginning - this is due to our random space filling sampling initially. We can also see that ImFil does not make much progress here. The GP-based sampling is used until 30 evaluations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d96c459",
   "metadata": {},
   "source": [
    "Note that the GP based optimizer has parameters, including the size of the initial experimental design, the number of iterations that we want to apply the GP (here 30), the maximum number of local searches with ImFil after the GP is done, .... see the __[opti_by_gp.py](opti_by_gp.py)__ module (or run the cell below to load)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040c5b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load 'opti_by_gp.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2b3451",
   "metadata": {},
   "source": [
    "**Exercise:** redo the above analysis using a noisy objective. If time is limited, consider only using sampling noise, e.g. by setting `shots=8192` (see the notebook on __[noise](hubbard_vqe_noise.ipynb)__ for more examples), and using tight bounds.\n",
    "\n",
    "**Optional Exercise:** for comparison purposes, follow-up with an optimization run that does not use GP and try in particular what happens when using only few function evaluations (20, say, if using tight bounds). Try different optimizers (but consider that some, such as SPSA, will take more evalations per iteration; and consider that optimizers that do not respect bounds are at a severe disadvantage)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffcb66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# noisy objective, adjust as desired\n",
    "objective = hb.EnergyObjective(hubbard_op, n_electrons_up, n_electrons_down,\n",
    "    trotter_steps=3, shots=8192, save_evals=True)\n",
    "\n",
    "# initial and bounds (set good=False to get loose bounds)\n",
    "initial_amplitudes, bounds = MODEL.initial(\n",
    "    n_electrons_up, n_electrons_down, objective.npar(), good=True)\n",
    "\n",
    "# max number of allowed function evals\n",
    "maxevals = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4973a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = obg.opti_by_gp(objective.npar(), bounds, objective, maxevals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d54eda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Results with GP:')\n",
    "print(\"Estimated energy: %.5f\" % result[1])\n",
    "print(\"Parameters:      \", result[0])\n",
    "print(\"Number of iters: \", result[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07434f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='samples.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdb7104",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='progress.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d6cb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull in a couple of optimizers to play with\n",
    "from qiskit.algorithms.optimizers import COBYLA, SPSA\n",
    "try:\n",
    "    from qiskit.algorithms.optimizers import IMFIL, SNOBFIT\n",
    "except ImportError:\n",
    "    print(\"install scikit-quant to use IMFIL and SNOBFIT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491f9e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = IMFIL(maxiter=maxevals).optimize(\n",
    "        num_vars = objective.npar(),\n",
    "        objective_function=objective,\n",
    "        initial_point = initial_amplitudes,\n",
    "        variable_bounds = bounds\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc47b5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ImFil results without GP:')\n",
    "print(\"Estimated energy: %.5f\" % result[1])\n",
    "print(\"Parameters:      \", result[0])\n",
    "print(\"Number of iters: \", result[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5b111c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = SPSA(maxiter=maxevals//2).optimize(    # note division by 2, but also check actual evals!\n",
    "        num_vars = objective.npar(),\n",
    "        objective_function=objective,\n",
    "        initial_point = initial_amplitudes,\n",
    "        variable_bounds = bounds\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec71ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('SPSA results without GP:')\n",
    "print(\"Estimated energy: %.5f\" % result[1])\n",
    "print(\"Parameters:      \", result[0])\n",
    "print(\"Number of iters: \", result[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
