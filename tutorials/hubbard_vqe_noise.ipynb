{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b5344a0",
   "metadata": {},
   "source": [
    "Effect of Noise on VQE\n",
    "==================\n",
    "\n",
    "The Variation Quantum Eigensolver (VQE) algorithm has multiple steps. The effect of noise at each individual step on the end result differs, with important consequences for the surface that the classical optimizer sees. On the face of it, noise reduction is always a good thing. However, VQE is also an iterative algorithm, which means that it has intermediate results that will be discarded after use; and has a classical sum, which means that some terms contribute more than others to the final result. Thus, not all noise is equally bad, and understanding the disparate impact allows setting up a workflow that best utilizes the available tools and resources (both quantum and classical).\n",
    "\n",
    "<img src='./figs/vqe_structure.png'>\n",
    "\n",
    "It is useful to recognize three main error categories:\n",
    "\n",
    "* initialization error\n",
    "* preparation error\n",
    "* measurement error\n",
    "\n",
    "**Initialization errors**, caused by gate errors in, or decay during, the creation of the initial state from the computational null state, effectively set up an incorrect configuration (e.g. more or fewer particles than intended, or of a different type). The effects may be large enough to flag shots with such errors in post-selection. Otherwise, the result is a, possibly biased, smearing of the final output distribution.\n",
    "\n",
    "**Preparation errors**, caused by gate errors in, or decay during, the Ansatz portion of the algorithm, result in a different trial state to be prepared than the optimizer intended. If the Ansatz is configuration preserving (this is typical), but the configuration of the trial state is now off due to the errors, then just like initialization errors, this may be detectable. More likely, the trial state is still close to, but not at, the intended state. Since all states with the correct configuration that are not the ground state result in an estimated energy higher than the minimum, the net effect is a \"lifting\" of the optimization surface.\n",
    "\n",
    "**Measurement errors**, which for this discussion includes errors in the base rotations gates, misclassification, and sampling errors, mean that effectively different components are measured than the ones that make up the chosen Hamiltonian (e.g. measuring 'IXYI' where 'XXYI' was intended because of a bit flip on qubit 0). If the components are different, the calculated Hamiltonian is different. Since the components are measured through independent experiments, the result will be an approximately Gaussian distribution in the limit (i.e. with many components in the Hamiltonian), because of the central limit theorem. Whether the result will be biased depends on the Hamiltonian, the prepared state, and the noise profile of the hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba4b05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hubbard as hb\n",
    "import noise_model as noise\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd40eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.getLogger('hubbard').setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ee4373",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> Running the full simulation may be too slow on a laptop in a (time-constrained) tutorial setting. It is recommended in that case to only run a few shots and simply use larger error settings to see the basic effects. The settings below reflect this recommendation.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd1aee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the number of processes to use in parallel\n",
    "n_processes = os.cpu_count() // 2\n",
    "\n",
    "# Number of evaluations per graph\n",
    "n_evals = max(8, n_processes)\n",
    "print(\"number of evaluations:\", n_evals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce8c5bb",
   "metadata": {},
   "source": [
    "Model Setup\n",
    "---------------\n",
    "\n",
    "In the examples below, we will use the same Hubbard Model setup as before. For proper comparison, consider the noise-free calculation of the ground energy on the Ansatz as this depends on the number of Trotter steps chosen, rather than the exact solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08df6cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a model appropriate for the machine used:\n",
    "#    laptop -> use small model\n",
    "#    server -> use medium model\n",
    "\n",
    "MODEL = hb.small_model\n",
    "#MODEL = hb.medium_model\n",
    "\n",
    "# Hubbard model for fermions (Fermi-Hubbard) required parameters\n",
    "xdim, ydim, t, U, chem, magf, periodic, spinless = MODEL()\n",
    "\n",
    "# Number of electrons to add to the system\n",
    "n_electrons_up   = 1\n",
    "n_electrons_down = 1\n",
    "n_electrons = n_electrons_up + n_electrons_down\n",
    "\n",
    "# Total number of \"sites\", with each qubit representing occupied or not\n",
    "spinfactor = spinless and 1 or 2\n",
    "n_qubits = n_sites = xdim * ydim * spinfactor\n",
    "\n",
    "# Create the Hubbard Model for use with Qiskit\n",
    "hubbard_op = hb.hamiltonian_qiskit(\n",
    "    x_dimension        = xdim,\n",
    "    y_dimension        = ydim,\n",
    "    tunneling          = t,\n",
    "    coulomb            = U,\n",
    "    chemical_potential = chem,\n",
    "    magnetic_field     = magf,\n",
    "    periodic           = periodic,\n",
    "    spinless           = spinless)\n",
    "\n",
    "# Retrieve the pre-calculated optimal parameters\n",
    "par_at_opt = MODEL.optimal(n_electrons_up, n_electrons_down)\n",
    "\n",
    "# Note that the estimate energy will be somewhat off, due to the\n",
    "# limited number of trotter steps (here: 2)\n",
    "print(\"expected: %.5f\" % hb.EnergyObjective(hubbard_op, n_electrons_up, n_electrons_down)(par_at_opt))\n",
    "print(\"exact:    %.5f\" % hb.exact(hubbard_op, n_electrons_up, n_electrons_down))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be35a624",
   "metadata": {},
   "source": [
    "Effect of Preparation Errors\n",
    "--------------------------------\n",
    "\n",
    "First, we will consider the effect of state preparation errors on the calculated energy at the optimal parameters by step-wise increasing the chances of polarization errors in single and 2-qubit gates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f67a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise step size and scale to use\n",
    "noise_scale = 10.\n",
    "noise_step_1q = 1.E-5 * (noise_scale/n_evals)\n",
    "noise_step_2q = 1.E-4 * (noise_scale/n_evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768dc03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(x, Y):\n",
    "    \"\"\"\\\n",
    "    Helper to plot results from the noise studies.\n",
    "    \n",
    "    Args:\n",
    "       x (tuple of (np.array, label)): x coordinates and label\n",
    "       Y (tuple of (np.array, label)) pairs: y coordinates and their label\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure()\n",
    "    for y, ylabel in Y:\n",
    "        plt.plot(x[0], y, label=ylabel)\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.xlabel(x[1])\n",
    "    plt.ylabel('expectation at optimum')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded0ee0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the first run with default settings for later use\n",
    "saved_result = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4b8652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following uses Python's multiprocessing. If this fails for you,\n",
    "# change it to a simple loop and run sequentially.\n",
    "with mp.Pool(n_processes) as p:\n",
    "    futs = []\n",
    "    for i in range(n_evals):\n",
    "        objective = hb.EnergyObjective(hubbard_op, n_electrons_up, n_electrons_down,\n",
    "            noise_model=noise.create(p_gate_1q=noise_step_1q*i, p_gate_2q=noise_step_2q*i),\n",
    "            trotter_steps=2)\n",
    "        futs.append(p.apply_async(objective, (par_at_opt,)))\n",
    "\n",
    "    result = [f.get() for f in futs]\n",
    "    \n",
    "# save the first run with default settings for later use\n",
    "if saved_result is None:\n",
    "    saved_result = result[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d088d80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph((range(n_evals), 'noise step'), [(result, 'uncorrected')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d3b1e2",
   "metadata": {},
   "source": [
    "Note that at low noise level, the effect of incremental noise is roughly linear, something that can be exploited in post-processing using the zero-noise extrapolation (ZNE) technique.$^{1,2}$\n",
    "\n",
    "**Exercise:** Change the number of Trotter steps, plot against the original results and explain the relative differences. What is better, more or fewer Trotter steps?\n",
    "\n",
    "**Exercise:** Increase the scale to some huge number (e.g. 1000); explain the asymptotic behavior.\n",
    "\n",
    "**Optional Exercise:** simulate single and 2-qubit gate noise independently and compare and explain the results. E.g., why do the results reach an asymptotic value at high noise?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4f4387",
   "metadata": {},
   "source": [
    "### Effect of BQSKit optimization\n",
    "\n",
    "Next, we'll add the BQSKit optimization step to see the improvement as a function of noise level of having fewer gates (in particular CNOTs) in the circuit. Note that the noise model chosen only considers depolarization errors and the overall improvement will be better than simulated here.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> BQSKit has randomized algorithms, so the result you get may be \"unlucky\" and that streak will be baked in, because the result will be used across all noise levels. Thus, if there are more than, say, 45 CNOTs left, consider rerunning the cell.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b18748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise step size and scale to use\n",
    "noise_scale = 10.\n",
    "noise_step_1q = 1.E-5 * (noise_scale/n_evals)\n",
    "noise_step_2q = 1.E-4 * (noise_scale/n_evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc3215b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save time, cache the BQSKit optimized circuit, then run through the\n",
    "# range of noise levels re-using this cached circuit\n",
    "\n",
    "result_bqskit = []\n",
    "\n",
    "# first run, with BQSKit optimization for the base case w/o noise (note:\n",
    "# if this is too slow, set 'run_bqskit=True' instead, which will run only\n",
    "# a single optimization round, rather than until full convergence)\n",
    "objective = hb.EnergyObjective(hubbard_op, n_electrons_up, n_electrons_down,\n",
    "    noise_model=None, trotter_steps=2, run_bqskit='full')\n",
    "result_bqskit.append(objective(par_at_opt, use_cached_circuit=True))\n",
    "\n",
    "# run over the remaining noise-levels, using the cached circuit\n",
    "with mp.Pool(n_processes) as p:\n",
    "    futs = []\n",
    "    for i in range(1, n_evals):\n",
    "        objective = hb.EnergyObjective(hubbard_op, n_electrons_up, n_electrons_down,\n",
    "            noise_model=noise.create(p_gate_1q=noise_step_1q*i, p_gate_2q=noise_step_2q*i),\n",
    "            trotter_steps=2, run_bqskit=True)\n",
    "        futs.append(p.apply_async(objective, (par_at_opt, hb.get_cached_circuit())))\n",
    "\n",
    "    result = [f.get() for f in futs]\n",
    "\n",
    "result_bqskit += result\n",
    "hb.clear_circuit_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e745b948",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph((range(n_evals), 'noise step'), [(saved_result, 'uncorrected'), (result_bqskit, 'with bqskit')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2394be08",
   "metadata": {},
   "source": [
    "<table style=\"padding: 0px\"><tr></tr><tr>\n",
    "<td style=\"width: 50%; padding: 0px\">\n",
    "<div align=\"left\" style=\"text-align: left; font-size: 120%\">\n",
    "As can be seen, the reduction in CNOT by BQSKit does not lead to a proportional reduction in the noise impact on the final result (as opposed to the impact of overall noise, which is seen to be roughly linear). This can be understood from the figure on the right: noise causes a deviation from the intended trial state, but the further away, the less of an impact the next random steps have, because the total volume to randomly step into has increased (from starting at zero, at the intended state).\n",
    "\n",
    "<br>This is similar to what happens in a (Gaussian) random walk distribution of fixed steps, where the distance from the starting point increases with $\\sqrt N$, with similar subdued impact from each additional step at large $N$.\n",
    "</div></td>\n",
    "    <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>\n",
    "<td style=\"width: 50%\">\n",
    "    <img src='./figs/stochastic_noise.png'>\n",
    "</td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c5492a",
   "metadata": {},
   "source": [
    "Effect of Measurement Errors\n",
    "-----------------------------------\n",
    "\n",
    "Classification errors are function of the readout quality, which is (assuming correct calibration) mostly a given for a specific hardware setup. Sampling error, however, can be reduced by increasing the number of shots. Increased sampling may or may not reduce the impact of misclassification, as those errors are possibly biased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3a104c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability of misclassification\n",
    "p_meas = 0.02\n",
    "\n",
    "# Number of evaluation points (Note: do not make this number too large,\n",
    "# see the exponentation in the inner loop below)\n",
    "n_meas_evals = n_evals * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc0d0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following uses Python's multiprocessing. If this fails for you,\n",
    "# change it to a simple loop and run sequentially.\n",
    "with mp.Pool(n_processes) as p:\n",
    "    futs = []\n",
    "    for i in range(n_meas_evals):\n",
    "        objective = hb.EnergyObjective(hubbard_op, n_electrons_up, n_electrons_down,\n",
    "            noise_model=noise.create(p_meas=p_meas), shots=2**(8+i/2),\n",
    "            trotter_steps=2)\n",
    "        futs.append(p.apply_async(objective, (par_at_opt,)))\n",
    "\n",
    "    result = [f.get() for f in futs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f87bd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(([2**(8+i/2) for i in range(n_meas_evals)], 'samples'), [(result, 'objective')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcf70a3",
   "metadata": {},
   "source": [
    "### Optional Exercises\n",
    "\n",
    "Consider the following possible studies (time consuming):\n",
    "\n",
    "* Simulate classification and sampling errors independently and compare\n",
    "* For a given classification error, find the point where further sampling does not improve the result\n",
    "* Plot full distributions of single-shot evaluations as a function of error level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a004e86",
   "metadata": {},
   "source": [
    "References\n",
    "-------------\n",
    "\n",
    "[1] https://arxiv.org/abs/1612.02058, K. Temme, S. Bravyi, J.M. Gambetta, \"Error Mitigation for Short-Depth Quantum Circuits\", Phys. Rev. Lett. 119(18), Dec. 2016\n",
    "<br>[2] https://arxiv.org/abs/1611.09301 Y. Li, S.C. Benjamin, \"Efficient Variational Quantum Simulator Incorporating Active Error Minimization\", Phys. Rev. X 7, 021050 (2017)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
